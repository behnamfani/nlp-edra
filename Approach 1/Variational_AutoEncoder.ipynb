{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, metrics, Model, losses\n",
        "import pandas as pd"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HuQATS3A49y8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Libraries*** ðŸ‘†\n",
        "---\n",
        "# ***Methods and Classes*** ðŸ‘‡\n"
      ],
      "metadata": {
        "id": "PgHC8q4GEZ0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Samling\n",
        "class Sampling(layers.Layer):\n",
        "  '''\n",
        "  Sampling Layer: Sample z from the Probability Distribution of z_mean and z_log_var\n",
        "  '''\n",
        "  def call(self, z_mean, z_log_var):\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.random.normal(shape=(batch, dim))\n",
        "    z = z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "    return z"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TF2lmw9i5De7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title VAE Model\n",
        "class VAE(keras.Model):\n",
        "\n",
        "  def __init__(self, input_dim:int, hidden_dim:int, latent_dim:int, **kwargs):\n",
        "    '''\n",
        "    Define the model structure and it's properties\n",
        "    '''\n",
        "    super().__init__(**kwargs)\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = self.Encoder()\n",
        "    self.decoder = self.Decoder()\n",
        "    self.total_loss = metrics.Mean(name=\"total_loss\")\n",
        "    self.reconstruction_loss = metrics.Mean(name=\"reconstruction_loss\")\n",
        "    self.kl_loss = metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    '''\n",
        "    Loss metrics\n",
        "    '''\n",
        "    return [self.total_loss, self.reconstruction_loss, self.kl_loss,]\n",
        "\n",
        "\n",
        "  def Encoder(self)->Model:\n",
        "    '''\n",
        "    Encoder model to transform the input to the latent space (compress)\n",
        "    '''\n",
        "    encoder_inputs = keras.Input(shape=(self.input_dim,))\n",
        "    x = layers.Dense(self.hidden_dim, activation=\"relu\")(encoder_inputs)\n",
        "    z_mean = layers.Dense(self.latent_dim, name=\"z_mean\")(x)\n",
        "    z_log_var = layers.Dense(self.latent_dim, name=\"z_log_var\")(x)\n",
        "    z = Sampling()(z_mean, z_log_var)\n",
        "    encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "    encoder.summary()\n",
        "    keras.utils.plot_model(encoder, show_shapes=True, to_file='Encoder.png')\n",
        "    return encoder\n",
        "\n",
        "\n",
        "  def Decoder(self)->Model:\n",
        "    '''\n",
        "    Decoder model to reconstruct the input from the latent vector  (decompress)\n",
        "    '''\n",
        "    latent_inputs = keras.Input(shape=(self.latent_dim,))\n",
        "    x = layers.Dense(self.hidden_dim, activation=\"relu\")(latent_inputs)\n",
        "    decoder_outputs = layers.Dense(self.input_dim, activation=\"relu\")(x)\n",
        "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "    decoder.summary()\n",
        "    keras.utils.plot_model(decoder, show_shapes=True, to_file='Decoder.png')\n",
        "    return decoder\n",
        "\n",
        "\n",
        "  def Loss(self, input: tf.Tensor, output: tf.Tensor, z_mean: tf.Tensor, z_log_var: tf.Tensor)->list:\n",
        "    '''\n",
        "    The Loss fuction to calculate the loss of VEA (Reconstruction_loss+KL_loss)\n",
        "    '''\n",
        "    Reconstruction_loss = tf.reduce_mean((input-output)**2)\n",
        "    KL_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
        "    KL_loss = tf.reduce_mean(tf.reduce_sum(KL_loss))\n",
        "    return [Reconstruction_loss + KL_loss, Reconstruction_loss, KL_loss]\n",
        "\n",
        "\n",
        "  def train_step(self, input: tf.Tensor)->dict:\n",
        "    '''\n",
        "    Calculate the output of the model and the errors.\n",
        "    Update the model's weights by Backpropagating the error\n",
        "    '''\n",
        "    with tf.GradientTape() as tape:\n",
        "      z_mean, z_log_var, z = self.encoder(input)\n",
        "      output = self.decoder(z)\n",
        "      Total_loss, Reconstruction_loss, KL_loss = self.Loss(input, output, z_mean, z_log_var)\n",
        "      grads = tape.gradient(Total_loss, self.trainable_weights)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "      self.total_loss.update_state(Total_loss)\n",
        "      self.reconstruction_loss.update_state(Reconstruction_loss)\n",
        "      self.kl_loss.update_state(KL_loss)\n",
        "      return { \"Loss\": self.total_loss.result(), \"Reconstruction_loss\": self.reconstruction_loss.result(), \"KL_loss\": self.kl_loss.result(),}"
      ],
      "metadata": {
        "id": "AP8qkts851zH",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Methods and Classes*** ðŸ‘†\n",
        "---\n",
        "# ***Main*** ðŸ‘‡"
      ],
      "metadata": {
        "id": "iNmn807kEt7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and train the model\n",
        "\n",
        "data = pd.read_pickle(\"/content/train_embeddings_1.p\")\n",
        "input_dim = data.shape[1]\n",
        "hidden_dim = 128\n",
        "latent_dim = 50\n",
        "\n",
        "vae = VAE(input_dim, hidden_dim, latent_dim)\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n",
        "vae.fit(data, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxBwMA8x9k2G",
        "outputId": "2379bb1a-39fb-43ff-d153-1d7f87be0bf7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 384)]        0           []                               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          49280       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 50)           6450        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 50)           6450        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 50)           0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 62,180\n",
            "Trainable params: 62,180\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               6528      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 384)               49536     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56,064\n",
            "Trainable params: 56,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "63/63 [==============================] - 3s 10ms/step - Loss: 17.2410 - Reconstruction_loss: 0.0565 - KL_loss: 17.1845\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 9ms/step - Loss: 0.9441 - Reconstruction_loss: 0.0357 - KL_loss: 0.9084\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 8ms/step - Loss: 0.3617 - Reconstruction_loss: 0.0353 - KL_loss: 0.3263\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 0s 8ms/step - Loss: 0.1885 - Reconstruction_loss: 0.0355 - KL_loss: 0.1530\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 0s 7ms/step - Loss: 0.1178 - Reconstruction_loss: 0.0354 - KL_loss: 0.0823\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 0s 7ms/step - Loss: 0.0725 - Reconstruction_loss: 0.0348 - KL_loss: 0.0377\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 0s 7ms/step - Loss: 0.0687 - Reconstruction_loss: 0.0348 - KL_loss: 0.0339\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 0s 6ms/step - Loss: 0.0531 - Reconstruction_loss: 0.0349 - KL_loss: 0.0182\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 0s 6ms/step - Loss: 0.0459 - Reconstruction_loss: 0.0345 - KL_loss: 0.0114\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 0s 7ms/step - Loss: 0.0431 - Reconstruction_loss: 0.0348 - KL_loss: 0.0082\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9d31c1d80>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the Trained encoder to get the compress vector\n",
        "\n",
        "trained_encoder = vae.encoder\n",
        "trained_encoder.trainable = False  # freeze the weights\n",
        "z_mean, z_log_var, z = trained_encoder.predict(data, verbose=0)"
      ],
      "metadata": {
        "id": "X8m-OUtSEaTg"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}