This file can be used as a base to create embeddings for the datasets. please before running install transformers with "!pip install -U sentence-transformers" or "conda install -c conda-forge sentence-transformers". The paraphrase-multilingual-MiniLM-L12-v2 is chosen as the SBERT model because it is 5 times faster than the best SBERT model and still offers good quality. Also, since the dataset is multilingual, this model has been trained over +50 languages and seems like a good match due to our resources, project, and dataset. Documentation:https://www.sbert.net/docs/pretrained_models.html
